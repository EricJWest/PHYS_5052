{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Round-Off Error in a Finite-Difference Approximation\n",
    "---\n",
    "**GOAL:** explore the effect that roundoff error has on a finite-difference approximation to a derivative\n",
    "\n",
    "**OUTCOMES:** after completing this activity, you will be able to do the following\n",
    "* measure absolute and relative error\n",
    "* create easy to read data tables\n",
    "* create log-log plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Introduction (Theory)\n",
    "Derivatives on a computer are approximated by finite differences. We can define the forward-difference operator $D_{h}$ as\n",
    "\n",
    "$$\n",
    "  D_{h}{f(x)} \\equiv \\frac{f(x + h) - f(x)}{h}\n",
    "$$\n",
    "\n",
    "where $h$ is a finite stepsize. Analytically we could take the limit as $h\\rightarrow 0$, which would yield the definition of the derivative of $f(x)$. But on a digital computer, we cannot take this limit, due to finite precision of representing floating point numbers. The best we can do is to make $h$ a small finite number. So we can take the forward-difference operator to be an approximation to the first derivative of a function\n",
    "\n",
    "$$\n",
    "  f'(x) \\approx D_{h}{f(x)}\n",
    "$$\n",
    "\n",
    "The hope is that this approximation will get better and better as $h$ is made smaller and smaller. To check this expectation, we will measure the error between an exact derivative and its approximation using the forward-difference equation above. We denote the absolute error as\n",
    "\n",
    "$$\n",
    "  E(x,h) = \\left|f'(x) - D_{h}{f(x)}\\right|\n",
    "$$\n",
    "\n",
    "and relative error as \n",
    "\n",
    "$$\n",
    "  \\mathcal{E}(x,h) = \\frac{E(x,h)}{|f'(x)|} = \\left|\\frac{f'(x) - D_{h}{f(x)}}{f'(x)}\\right|\n",
    "$$\n",
    "\n",
    "We want to study how $E(x,h)$ and $\\mathcal{E}(x,h)$ behave with varying $h$. To do this, we consider a function whose derivative we can calculate exactly. For example, let's take $f(x)=x^2$, so that $f'(x)=2x$. (NOTE: you could repeat this exercise for any other function whose derivative you know how to calculate.) We will evaluate $E(x,h)$ and $\\mathcal{E}(x,h)$ at $x=1$ for several values of $h$. We then plot $E(1,h)$ and $\\mathcal{E}(1,h)$ as functions of stepsize $h$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Functions\n",
    "Start by defining the functions we will need.\n",
    "\n",
    "- Exact function: $f(x)=x^2$\n",
    "- Exact dierivative: $f'(x)=2x$\n",
    "- Forward-difference approximation: $D_{h}f(x) = \\left|\\frac{f(x+h)-f(x)}{h}\\right|$\n",
    "- Absolute error: $E(x,h) = |f'(x) - D_{h}f(x)|$\n",
    "- Relative error: $\\mathcal{E}(x,h) = \\frac{E(x,h)}{|f'(x)|}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define functions ###\n",
    "\n",
    "## exact function\n",
    "\n",
    "## exact derivative\n",
    "    \n",
    "## finite-difference approximation\n",
    "\n",
    "## absolute error\n",
    "\n",
    "## relative error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test\n",
    "Test your functions for some known values. For example, work out by hand the results of these functions for $x=3$ and $h=1$. Check that your functions agree with those hand calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test functions for x=3, h=1 ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Table\n",
    "Create an array of h-values, $h = [10^{0}, 10^{-1}, 10^{-2}, ..., 10^{-20}]$. [NOTE: this is an array with values that are logarithmically spaced, instead of linearly spaced. To create such arrays, you can use logspace instead of linspace. Try it!]\n",
    "Then create an easy-to-read table with columns corresponding to: log(h) (i.e., $\\log_{10}(h)$), fd approximation (i.e., $D_{h}f(1)$) , absolute error (i.e., $E(1,h)$), and relative error (i.e., $\\mathcal{E}(1,h)$).\n",
    "\n",
    "OPTIONAL: put your table code inside of a function, so that the table is created by a simple function call. This is often called \"wrapping\" a function around some code fragment, or \"wrapping\" a code fragment inside of a function. This is an example of trying to write \"modular\" code, which often helps keep code well-organized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import libraries\n",
    "\n",
    "## set x value\n",
    "\n",
    "## create grid of h values (base 10)\n",
    "#hs = np.logspace()\n",
    "#print(hs)\n",
    "\n",
    "## table\n",
    "print(\"log(h) \\t fd approximation \\t absolute error \\t relative error\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Plot Error vs Stepsize\n",
    "Plot the error vs stepsize on a log-log plot (base 10). Plot both absolute error and relative error on the same graph (with different marker styles and/or colors). [NOTE: as you would when plotting experimental data, you should make a point/scatter plot, not a line plot. In other words, there should not be lines that \"connect the dots\" of your data, only the data points themselves.]\n",
    "\n",
    "OPTIONAL: wrap your graphing code inside of a function, so that the plot is created by a simple function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set graphics backend (for Jupyter notebook only)\n",
    "#%matplotlib notebook\n",
    "\n",
    "## import libraries\n",
    "\n",
    "## set x value\n",
    "\n",
    "## create grid of h values (base 10)\n",
    "\n",
    "## plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Interpret\n",
    "First, make sure that your table and graph agree with one another. They should both be showing the same thing, the same behavior. Second, interpret this behavior. What's going on? Why does the error do what it does? (NOTE: there should be three distinct regions where the error is doing something different. Explain what is going on in each of these regions, and why.)\n",
    "\n",
    "Statement: the finite-difference approximation to a derivative can be made arbitrarily accurate by just making the stepsize $h$ arbitrarily close to zero. **Explain why this statement is very sadly mistaken!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export to Script\n",
    "Once debugged, put working code into a script file that writes the table to a .txt file and saves the figure to a .pdf file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile main.py\n",
    "## import libraries\n",
    "import sys\n",
    "\n",
    "## set x value\n",
    "\n",
    "## create grid of h values (base 10)\n",
    "\n",
    "## table\n",
    "sys.stdout = open('table.txt', 'w')\n",
    "### TABLE FUNCTION HERE ###\n",
    "sys.stdout.close()\n",
    "\n",
    "## plot\n",
    "plt.ioff()\n",
    "### PLOT FUNCTION HERE ###\n",
    "plt.show()\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
